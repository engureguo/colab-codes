{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM45jMVlPLky1FTe/JLwnSj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/engureguo/colab-codes/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iEEVb6gybvjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6327875-422f-4d0f-cbe7-04efd70b2c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## quick tour"
      ],
      "metadata": {
        "id": "tB2nNY1geYNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets torch timm"
      ],
      "metadata": {
        "id": "2d3-TLdqeaVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `pipeline()` is the easiest and fastest way to use a pretrained model for inference. You can use the pipeline() out-of-the-box for many tasks across different modalities.\n",
        "\n",
        "pipeline API reference: https://huggingface.co/docs/transformers/main_classes/pipelines\n",
        "\n",
        "task summary & What Transformers can do?: https://huggingface.co/docs/transformers/task_summary\n"
      ],
      "metadata": {
        "id": "RI7NNMxsepM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "segmenter = pipeline(task=\"image-segmentation\")\n",
        "\n",
        "def segmenting(path:str):\n",
        "  preds = segmenter(path)\n",
        "  preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
        "  print(*preds, sep=\"\\n\")\n",
        "  print('--------------------------------------------')\n",
        "\n",
        "# segmenting('/content/p1.jpg')\n",
        "# segmenting('/content/p2.jpg')\n",
        "# segmenting('/content/p3.jpg')\n",
        "# segmenting('/content/p4.jpg')\n",
        "# segmenting('/content/p5.jpg')\n",
        "# segmenting('/content/p6.jpg')\n"
      ],
      "metadata": {
        "id": "f_KO0ZDzefvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "depth_estimator = pipeline(task=\"depth-estimation\")\n",
        "preds = depth_estimator(\"/content/p8.jpg\")\n",
        "\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jvFP53NhJeY",
        "outputId": "9e67db33-2444-46b7-b5b7-661611e9c33d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to Intel/dpt-large and revision e93beec (https://huggingface.co/Intel/dpt-large).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution1.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'predicted_depth': tensor([[[ 0.4473,  0.4696,  0.4768,  ...,  0.2688,  0.3006,  0.2269],\n",
            "         [ 0.4842,  0.5039,  0.5082,  ...,  0.3008,  0.3448,  0.3221],\n",
            "         [ 0.5441,  0.5454,  0.5637,  ...,  0.3206,  0.3550,  0.3364],\n",
            "         ...,\n",
            "         [16.6691, 16.7446, 16.7471,  ..., 17.2428, 17.2447, 17.2159],\n",
            "         [16.7485, 16.7324, 16.7714,  ..., 17.2329, 17.2586, 17.2636],\n",
            "         [16.7289, 16.7425, 16.7765,  ..., 17.2729, 17.2943, 17.2212]]]), 'depth': <PIL.Image.Image image mode=L size=401x601 at 0x7F2698F96380>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dADJDzNCmazp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}